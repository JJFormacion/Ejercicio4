{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ssl\n",
    "import urllib\n",
    "from sklearn.compose import make_column_selector as selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar los tres datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear un contexto SSL no verificado\n",
    "context = ssl._create_unverified_context()\n",
    "\n",
    "# Base URL para los datasets\n",
    "\n",
    "base_url = \"https://raw.githubusercontent.com/ricardoahumada/DataExpert/main/etapa4/data/\"\n",
    "\n",
    "\n",
    "# Función para descargar y cargar el dataset\n",
    "def load_dataset(url):\n",
    "    try:\n",
    "        with urllib.request.urlopen(url, context=context) as response:\n",
    "            return pd.read_csv(response)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar los datos: {str(e)}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datasets\n",
    "df_original_caracteristicas_equipos = load_dataset(base_url + 'Caracteristicas_Equipos.csv')\n",
    "df_original_historico_ordenes = load_dataset(base_url + 'Historicos_Ordenes.csv')\n",
    "df_original_registros_condiciones = load_dataset(base_url + 'Registros_Condiciones.csv')\n",
    "\n",
    "if df_original_caracteristicas_equipos is not None and df_original_historico_ordenes is not None and df_original_registros_condiciones is not None:\n",
    "    print(\"Cargados correctamente.\")\n",
    "else:\n",
    "    print(\"Error al cargar uno o más datasets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar copia en local:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los guardamos en local los originales para no depender.\n",
    "\n",
    "df_original_caracteristicas_equipos.to_csv(\"../data/df_caracteristicas_equipos.csv\", index=False)\n",
    "df_original_historico_ordenes.to_csv(\"../data/df_historico_ordenes.csv\", index=False)\n",
    "df_original_registros_condiciones.to_csv(\"../data/df_registros_condiciones.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar los tres datasets desde local:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los tres datasets desde local:\n",
    "\n",
    "\n",
    "try:\n",
    "    df_trabajo_caracteristicas_equipos = pd.read_csv(\"../data/df_caracteristicas_equipos.csv\")\n",
    "    df_trabajo_historico_ordenes = pd.read_csv(\"../data/df_historico_ordenes.csv\")\n",
    "    df_trabajo_registros_condiciones = pd.read_csv(\"../data/df_registros_condiciones.csv\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar los datos: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesado por separado:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar Nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_nulos(df):\n",
    "\n",
    "# Esta función verifica si hay valores nulos en el DataFrame.\n",
    "    \n",
    "    nulos = df.isnull().sum().sum()\n",
    "    print(\"Numero nulos=\" + str(nulos))\n",
    "\n",
    "    if nulos != 0:\n",
    "        df.dropna(inplace=True)\n",
    "        print(\"Valores nulos eliminados\")\n",
    "    else:\n",
    "        print(\"No hay valores nulos\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype \n",
      "---  ------                       --------------  ----- \n",
      " 0   ID_Equipo                    500 non-null    int64 \n",
      " 1   Tipo_Equipo                  500 non-null    object\n",
      " 2   Fabricante                   500 non-null    object\n",
      " 3   Modelo                       500 non-null    object\n",
      " 4   Potencia_kW                  500 non-null    int64 \n",
      " 5   Horas_Recomendadas_Revision  500 non-null    int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 23.6+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61726 entries, 0 to 61725\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   ID_Orden             61726 non-null  int64 \n",
      " 1   ID_Equipo            61726 non-null  int64 \n",
      " 2   Fecha                61726 non-null  object\n",
      " 3   Tipo_Mantenimiento   61726 non-null  object\n",
      " 4   Costo_Mantenimiento  61726 non-null  int64 \n",
      " 5   Duracion_Horas       61726 non-null  int64 \n",
      " 6   Ubicacion            61726 non-null  object\n",
      "dtypes: int64(4), object(3)\n",
      "memory usage: 3.3+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 730500 entries, 0 to 730499\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   ID_Registro       730500 non-null  int64  \n",
      " 1   ID_Equipo         730500 non-null  int64  \n",
      " 2   Fecha             730500 non-null  object \n",
      " 3   Temperatura_C     730500 non-null  float64\n",
      " 4   Vibracion_mm_s    730500 non-null  float64\n",
      " 5   Horas_Operativas  730500 non-null  int64  \n",
      "dtypes: float64(2), int64(3), object(1)\n",
      "memory usage: 33.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_trabajo_caracteristicas_equipos.info())\n",
    "print(df_trabajo_historico_ordenes.info())\n",
    "print(df_trabajo_registros_condiciones.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero nulos=0\n",
      "No hay valores nulos\n",
      "Numero nulos=0\n",
      "No hay valores nulos\n",
      "Numero nulos=0\n",
      "No hay valores nulos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eliminar_nulos(df_trabajo_caracteristicas_equipos)\n",
    "eliminar_nulos(df_trabajo_historico_ordenes)\n",
    "eliminar_nulos(df_trabajo_registros_condiciones)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar duplicados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_duplicados(df):\n",
    "\n",
    "    # Identificar duplicados\n",
    "    duplicados = df[df.duplicated()]\n",
    "    print(\"Duplicados encontrados antes de la eliminación:\")\n",
    "    print(duplicados)\n",
    "\n",
    "    # Contar duplicados por columna\n",
    "    duplicados_count = df.duplicated().sum()\n",
    "    print(f\"Total de duplicados: {duplicados_count}\")\n",
    "\n",
    "    # Eliminar duplicados\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(\"Duplicados eliminados.\")\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados encontrados antes de la eliminación:\n",
      "Empty DataFrame\n",
      "Columns: [ID_Equipo, Tipo_Equipo, Fabricante, Modelo, Potencia_kW, Horas_Recomendadas_Revision]\n",
      "Index: []\n",
      "Total de duplicados: 0\n",
      "Duplicados eliminados.\n",
      "Duplicados encontrados antes de la eliminación:\n",
      "Empty DataFrame\n",
      "Columns: [ID_Orden, ID_Equipo, Fecha, Tipo_Mantenimiento, Costo_Mantenimiento, Duracion_Horas, Ubicacion]\n",
      "Index: []\n",
      "Total de duplicados: 0\n",
      "Duplicados eliminados.\n",
      "Duplicados encontrados antes de la eliminación:\n",
      "Empty DataFrame\n",
      "Columns: [ID_Registro, ID_Equipo, Fecha, Temperatura_C, Vibracion_mm_s, Horas_Operativas]\n",
      "Index: []\n",
      "Total de duplicados: 0\n",
      "Duplicados eliminados.\n"
     ]
    }
   ],
   "source": [
    "procesar_duplicados(df_trabajo_caracteristicas_equipos)\n",
    "procesar_duplicados(df_trabajo_historico_ordenes)\n",
    "procesar_duplicados(df_trabajo_registros_condiciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inconsistencias numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corregir_inconsistencias_numericas(df):\n",
    "    # Selección de columnas numéricas\n",
    "    numerical_columns_selector = selector(dtype_exclude=object)\n",
    "    numerical_columns = numerical_columns_selector(df)\n",
    "\n",
    "    # Corregir inconsistencias en campos numéricos\n",
    "    for col_name in numerical_columns:\n",
    "        df[col_name] = pd.to_numeric(df[col_name], errors='coerce')\n",
    "        df[col_name].fillna(df[col_name].median(), inplace=True)\n",
    "        print(f\"Inconsistencias corregidas en la columna numérica '{col_name}'.\")\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corregir_inconsistencias_numericas(df_trabajo_caracteristicas_equipos)\n",
    "#corregir_inconsistencias_numericas(df_trabajo_historico_ordenes)\n",
    "#corregir_inconsistencias_numericas(df_trabajo_registros_condiciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers a efectos practicos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_outliers(df):\n",
    "  \n",
    "    # Esta función identifica y winsoriza outliers en las columnas numéricas de un DataFrame.\n",
    "\n",
    "    # Selección de columnas numéricas\n",
    "    numerical_columns_selector = selector(dtype_exclude=object)\n",
    "    numerical_columns = numerical_columns_selector(df)\n",
    "\n",
    "    # Identificación de outliers\n",
    "    IQR = df[numerical_columns].quantile(0.75) - df[numerical_columns].quantile(0.25)\n",
    "    lower_bound = df[numerical_columns].quantile(0.25) - (IQR * 1.5)\n",
    "    upper_bound = df[numerical_columns].quantile(0.75) + (IQR * 1.5)\n",
    "\n",
    "    # Función para winsorizar una columna\n",
    "    def winsorize_column(column, lower_bound, upper_bound):\n",
    "        return column.clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "\n",
    "    # Identificar y mostrar outliers antes de winsorización\n",
    "    outliers = df[numerical_columns][(df[numerical_columns] < lower_bound) | (df[numerical_columns] > upper_bound)]\n",
    "    print(\"Outliers encontrados antes de winsorización:\")\n",
    "    print(outliers)\n",
    "\n",
    "# Mostrar la suma de outliers por columna\n",
    "    outliers_count = outliers.count()\n",
    "    print(\"Los outlayers encontrados, suma total por columna:\")\n",
    "    for col_name, count in outliers_count.items():\n",
    "        print(f\"{col_name}: {count}\")\n",
    "\n",
    "    # Procesar todas las columnas con outliers\n",
    "    for col_name in numerical_columns:\n",
    "        df[col_name] = winsorize_column(df[col_name], lower_bound[col_name], upper_bound[col_name])\n",
    "\n",
    "    # Verificar outliers después de winsorización\n",
    "    outliers = df[numerical_columns][(df[numerical_columns] < lower_bound) | (df[numerical_columns] > upper_bound)]\n",
    "    print(\"Outliers - winsorized:\")\n",
    "    print(outliers.count())\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers encontrados antes de winsorización:\n",
      "     ID_Equipo  Potencia_kW  Horas_Recomendadas_Revision\n",
      "0          NaN          NaN                          NaN\n",
      "1          NaN          NaN                          NaN\n",
      "2          NaN          NaN                          NaN\n",
      "3          NaN          NaN                          NaN\n",
      "4          NaN          NaN                          NaN\n",
      "..         ...          ...                          ...\n",
      "495        NaN          NaN                          NaN\n",
      "496        NaN          NaN                          NaN\n",
      "497        NaN          NaN                          NaN\n",
      "498        NaN          NaN                          NaN\n",
      "499        NaN          NaN                          NaN\n",
      "\n",
      "[500 rows x 3 columns]\n",
      "Los outlayers encontrados, suma total por columna:\n",
      "ID_Equipo: 0\n",
      "Potencia_kW: 0\n",
      "Horas_Recomendadas_Revision: 0\n",
      "Outliers - winsorized:\n",
      "ID_Equipo                      0\n",
      "Potencia_kW                    0\n",
      "Horas_Recomendadas_Revision    0\n",
      "dtype: int64\n",
      "Outliers encontrados antes de winsorización:\n",
      "       ID_Orden  ID_Equipo  Costo_Mantenimiento  Duracion_Horas\n",
      "0           NaN        NaN                  NaN             NaN\n",
      "1           NaN        NaN                  NaN             NaN\n",
      "2           NaN        NaN                  NaN             NaN\n",
      "3           NaN        NaN                  NaN             NaN\n",
      "4           NaN        NaN                  NaN             NaN\n",
      "...         ...        ...                  ...             ...\n",
      "61721       NaN        NaN                  NaN             NaN\n",
      "61722       NaN        NaN                  NaN             NaN\n",
      "61723       NaN        NaN                  NaN             NaN\n",
      "61724       NaN        NaN                  NaN             NaN\n",
      "61725       NaN        NaN                  NaN             NaN\n",
      "\n",
      "[61726 rows x 4 columns]\n",
      "Los outlayers encontrados, suma total por columna:\n",
      "ID_Orden: 0\n",
      "ID_Equipo: 0\n",
      "Costo_Mantenimiento: 0\n",
      "Duracion_Horas: 0\n",
      "Outliers - winsorized:\n",
      "ID_Orden               0\n",
      "ID_Equipo              0\n",
      "Costo_Mantenimiento    0\n",
      "Duracion_Horas         0\n",
      "dtype: int64\n",
      "Outliers encontrados antes de winsorización:\n",
      "        ID_Registro  ID_Equipo  Temperatura_C  Vibracion_mm_s  \\\n",
      "0               NaN        NaN            NaN             NaN   \n",
      "1               NaN        NaN            NaN             NaN   \n",
      "2               NaN        NaN            NaN             NaN   \n",
      "3               NaN        NaN            NaN             NaN   \n",
      "4               NaN        NaN            NaN             NaN   \n",
      "...             ...        ...            ...             ...   \n",
      "730495          NaN        NaN            NaN             NaN   \n",
      "730496          NaN        NaN            NaN             NaN   \n",
      "730497          NaN        NaN            NaN             NaN   \n",
      "730498          NaN        NaN            NaN             NaN   \n",
      "730499          NaN        NaN            NaN             NaN   \n",
      "\n",
      "        Horas_Operativas  \n",
      "0                    NaN  \n",
      "1                    NaN  \n",
      "2                    NaN  \n",
      "3                    NaN  \n",
      "4                    NaN  \n",
      "...                  ...  \n",
      "730495               NaN  \n",
      "730496               NaN  \n",
      "730497               NaN  \n",
      "730498               NaN  \n",
      "730499               NaN  \n",
      "\n",
      "[730500 rows x 5 columns]\n",
      "Los outlayers encontrados, suma total por columna:\n",
      "ID_Registro: 0\n",
      "ID_Equipo: 0\n",
      "Temperatura_C: 0\n",
      "Vibracion_mm_s: 0\n",
      "Horas_Operativas: 34114\n",
      "Outliers - winsorized:\n",
      "ID_Registro         0\n",
      "ID_Equipo           0\n",
      "Temperatura_C       0\n",
      "Vibracion_mm_s      0\n",
      "Horas_Operativas    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "procesar_outliers(df_trabajo_caracteristicas_equipos)\n",
    "procesar_outliers(df_trabajo_historico_ordenes)\n",
    "procesar_outliers(df_trabajo_registros_condiciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformacion fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformar_fechas(df):\n",
    "\n",
    "    # Selección de columnas de tipo fecha\n",
    "    date_columns_selector = selector(dtype_include='object')\n",
    "    date_columns = date_columns_selector(df)\n",
    "\n",
    "    # Transformar columnas de fecha a formato datetime\n",
    "    for col_name in date_columns:\n",
    "        try:\n",
    "            df[col_name] = pd.to_datetime(df[col_name])\n",
    "            print(f\"Columna '{col_name}' transformada a formato datetime.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al transformar la columna '{col_name}': {e}\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevas columnas, se me ocurren diferencias entre fechas de correctivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informacion tabla ordenes: df_trabajo_historico_ordenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nueva columna frecuencia de correctivo por equipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar solo los registros de mantenimiento correctivo\n",
    "df_mantenimiento_correctivo = df_trabajo_historico_ordenes[df_trabajo_historico_ordenes['Tipo_Mantenimiento'] == 'Correctivo']\n",
    "\n",
    "# Calcular la frecuencia de mantenimiento correctivo para cada equipo\n",
    "df_frecuencia_mantenimiento_correctivo = df_mantenimiento_correctivo['ID_Equipo'].value_counts()\n",
    "\n",
    "# Mapear la frecuencia al dataframe del histórico de órdenes\n",
    "df_trabajo_historico_ordenes['Frecuencia de mantenimiento correctivo'] = df_trabajo_historico_ordenes['ID_Equipo'].map(df_frecuencia_mantenimiento_correctivo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informacion tabla ordenes: df_trabajo_registros_condiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 730500 entries, 0 to 730499\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   ID_Registro       730500 non-null  int64  \n",
      " 1   ID_Equipo         730500 non-null  int64  \n",
      " 2   Fecha             730500 non-null  object \n",
      " 3   Temperatura_C     730500 non-null  float64\n",
      " 4   Vibracion_mm_s    730500 non-null  float64\n",
      " 5   Horas_Operativas  730500 non-null  int64  \n",
      "dtypes: float64(2), int64(3), object(1)\n",
      "memory usage: 33.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_trabajo_registros_condiciones.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabado de fichero de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trabajo_caracteristicas_equipos.to_csv(\"../output/df_caracteristicas_equipos_tratados.csv\", index=False)\n",
    "df_trabajo_historico_ordenes.to_csv(\"../output/df_historico_ordenes_tratados.csv\", index=False)\n",
    "df_trabajo_registros_condiciones.to_csv(\"../output/df_registros_condiciones_tratados.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lectura ficheros de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_trabajo_caracteristicas_equipos = pd.read_csv(\"../output/df_caracteristicas_equipos_tratados.csv\")\n",
    "    df_trabajo_historico_ordenes = pd.read_csv(\"../output/df_historico_ordenes_tratados.csv\")\n",
    "    df_trabajo_registros_condiciones = pd.read_csv(\"../output/df_registros_condiciones_tratados.csv\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar los datos: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Renombrar las columnas de fecha\n",
    "df_trabajo_registros_condiciones.rename(columns={'Fecha': 'Fecha_Condiciones'}, inplace=True)\n",
    "df_trabajo_historico_ordenes.rename(columns={'Fecha': 'Fecha_Ordenes'}, inplace=True)\n",
    "\n",
    "# Convertir las columnas de fecha a formato datetime\n",
    "df_trabajo_registros_condiciones['Fecha_Condiciones'] = pd.to_datetime(df_trabajo_registros_condiciones['Fecha_Condiciones'])\n",
    "df_trabajo_historico_ordenes['Fecha_Ordenes'] = pd.to_datetime(df_trabajo_historico_ordenes['Fecha_Ordenes'])\n",
    "\n",
    "\n",
    "# Fusionar los dataframes en 'ID_Equipo' y 'Fecha'\n",
    "merged_df = pd.merge(df_trabajo_registros_condiciones, df_trabajo_caracteristicas_equipos, on='ID_Equipo', how='left')\n",
    "merged_df = pd.merge(merged_df, df_trabajo_historico_ordenes, left_on=['ID_Equipo', 'Fecha_Condiciones'], right_on=['ID_Equipo', 'Fecha_Ordenes'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Eliminar las columnas especificadas\n",
    "columnas_a_eliminar = ['Fecha_Ordenes', 'ID_Orden', 'Tipo_Equipo', 'ID_Registro','Potencia_kW', 'Fabricante', 'Modelo', 'Costo_Mantenimiento', 'Duracion_Horas', 'Ubicacion', 'Frecuencia de mantenimiento correctivo']\n",
    "merged_df = merged_df.drop(columns=columnas_a_eliminar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Rellenar los valores NaN en la columna Tipo_Mantenimiento con \"sin\"\n",
    "merged_df['Tipo_Mantenimiento'] = merged_df['Tipo_Mantenimiento'].fillna('sin')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardado Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el dataframe final mezclado en un nuevo archivo CSV\n",
    "merged_df.to_csv('../output/Datos_Fusionadosv1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Netmind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
